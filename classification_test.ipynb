{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torchmetrics\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a85882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list={\n",
    "    'background':0,\n",
    "    'Tumor':1,\n",
    "    'Stroma':2,\n",
    "    'Immune cells':3,\n",
    "    'Necrosis':4,\n",
    "    'alveoli':5,\n",
    "    'Other':6\n",
    "}\n",
    "params={'image_size':128,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':32,\n",
    "        'epochs':200,\n",
    "        'n_classes':len(class_list),\n",
    "        'inch':3,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac587a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self,parmas, images,label):\n",
    "        \n",
    "        self.images = images\n",
    "        self.args=parmas\n",
    "        self.label=label\n",
    "        \n",
    "    def trans(self,image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index]\n",
    "        label=self.label[index]\n",
    "        image = self.trans(image)\n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "test_image_label=[]\n",
    "test_image_path=[]\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(class_list))):\n",
    "    image_list=glob(f'../../data/MIHIC/test/{list(class_list.keys())[i]}/*.png')\n",
    "    test_image_path.extend(image_list)\n",
    "    for k in range(len(image_list)):\n",
    "        test_image_label.append(i)\n",
    "\n",
    "test_images=torch.zeros((len(test_image_path),params['inch'],params['image_size'],params['image_size']))\n",
    "for i in tqdm(range(len(test_image_path))):\n",
    "    test_images[i]=trans(Image.open(test_image_path[i]).convert('RGB'))\n",
    "\n",
    "test_dataset=CustomDataset(params,test_images,F.one_hot(torch.tensor(test_image_label)).to(torch.int64))\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=params['batch_size'],shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72151ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('tf_efficientnetv2_s', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(custom_model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size, 2048, 1, 1)\n",
    "        \n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, _BatchNorm):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "            \n",
    "import transformers\n",
    "\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = custom_model(len(class_list),1280,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "base_optimizer = torch.optim.SGD\n",
    "# optimizer = SAM(model.parameters(), base_optimizer, lr=params['lr'], momentum=0.9)\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "model.load_state_dict(torch.load('../../model/IHC_Tissue_Region_classification/check.pt'))\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(class_list)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 결과 분석 및 시각화\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(model, dataloader, device, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    return all_labels, all_preds, all_probs\n",
    "\n",
    "# 클래스 이름 리스트\n",
    "class_names = list(class_list.keys())\n",
    "\n",
    "# 평가 실행\n",
    "labels, preds, probs = evaluate_model(model, test_dataloader, device, class_names)\n",
    "\n",
    "# 혼동 행렬\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 정밀도, 재현율, F1-score 등 상세 리포트\n",
    "report = classification_report(labels, preds, target_names=class_names, digits=4, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "display(df_report)\n",
    "\n",
    "# 전체 accuracy, macro/micro 평균 등\n",
    "print('전체 정확도(Accuracy):', report['accuracy'])\n",
    "print('Macro 평균 F1:', report['macro avg']['f1-score'])\n",
    "print('Weighted 평균 F1:', report['weighted avg']['f1-score'])\n",
    "\n",
    "# ROC Curve 및 AUC (One-vs-Rest, 다중 클래스)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(class_names)\n",
    "labels_onehot = F.one_hot(torch.tensor(labels), num_classes=n_classes).numpy()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels_onehot[:, i], probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (One-vs-Rest)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve 및 AP\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(labels_onehot[:, i], probs[:, i])\n",
    "    ap = average_precision_score(labels_onehot[:, i], probs[:, i])\n",
    "    plt.plot(recall, precision, label=f'{class_names[i]} (AP = {ap:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (One-vs-Rest)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 클래스별 샘플 수 및 분포\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x=labels, palette='Set2')\n",
    "plt.xticks(ticks=range(n_classes), labels=class_names, rotation=45)\n",
    "plt.title('Test Set Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# 논문 작성용 요약\n",
    "print('--- 논문용 분류 성능 요약 ---')\n",
    "for cls in class_names:\n",
    "    print(f\"{cls:12s} | Precision: {report[cls]['precision']:.4f} | Recall: {report[cls]['recall']:.4f} | F1: {report[cls]['f1-score']:.4f}\")\n",
    "print(f\"전체 정확도: {report['accuracy']:.4f}\")\n",
    "print(f\"Macro 평균 F1: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted 평균 F1: {report['weighted avg']['f1-score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
